---
Title: TimeFuzeアーキテクチャ構想 - 処理とデータとタイマーを一体化した定期データパイプライン
Category:
- Architecture
Date: 2017-12-20T23:30:44+09:00
URL: http://blog.yuuk.io/entry/2017/timefuze-architecture
EditURL: https://blog.hatena.ne.jp/y_uuki/yuuki.hatenablog.com/atom/entry/8599973812328408485
Draft: true
CustomPath: 2017/timefuze-architecture
---

この記事は[第1回ウェブシステムアーキテクチャ(WSA)研究会](http://websystemarchitecture.hatenablog.jp/)の予稿です。

cronのようなタイムスケジューラーにより、定期的に実行されるバッチ処理の課題を解決するアーキテクチャを最近考えている。
この記事では、サーバなどの処理主体がタスクスケジューリングするcronベースの手法に代えて、データに対してタイマーと処理を仕込むことでスケールさせやすい構造にできないか、という提案を試みる。この構造変更を「TimeFuzeアーキテクチャ」と呼ぶこととする。

# はじめに

Webサービスにおいて、ユーザーが発生させるイベントとは異なり、任意の時間周期で任意のバッチ処理を実行させたいことがある。
例えば、課金機能のための月次集計処理、機械学習のための学習モデルの定期更新などがある。
一般的な手法では、特定サーバ上のcronなどのタイムスケジューラーにより、バッチ処理を実行させる。

以前開発した時系列データベースアーキテクチャ[[yuu17]](http://blog.yuuk.io/entry/the-rebuild-of-tsdb-on-cloud)では、特性の異なる3種類の分散データストアを組み合わせ、古いデータを遅いディスクへ徐々に逃していくことにより、性能とコストを最適化した。データストア実装として、インメモリDB（Redis Cluster）、オンディスクDB（Amazon DynamoDB）、オブジェクトストレージ（Amazon S3）を採用している。
このアーキテクチャを考える上で重要なのは、どのようにデータを移動させるかということだった。
前述の一般的な手法により、データレコードを走査し、一定以上古いタイムスタンプをもつレコードを読み出し、次のデータストアへ書き込むという素朴な手法をまず考えた。

この手法は、SRE本[Bet17]の25.1節「パイプラインのデザインパターンの起源」にあるように、データパイプラインと定義されるデザインパターンに分類できる。

>
データ処理に対する旧来のアプローチは、データを読み取り、希望する何らかの方法でそのデー タを変換し、新しいデータを出力するプログラムを書くというものでした。通常こういったプログラムは、cron のような定期スケジューリングを行うプログラムの制御の下でスケジュール実行されました。このデザインパターンはデータパイプラインと呼ばれます。
> 「SRE サイトリライアビリティエンジニアリング ――Googleの信頼性を支えるエンジニアリングチーム」

定期データパイプラインの欠点として、25.3節「定期的なパイプラインパターンでの課題」にて、期限内に実行が終わらないジョブ、リソースの枯渇、処理の進まないチャンクとそれに伴う運用負荷が挙げられている。
時系列データベースの例では、レコード数が増加するにつれ、ジョブの実行時間が増加し、アプリケーションが想定する時間内に終わらない可能性がある。
ジョブの実行時間を減らすために、バッチ処理の並列度を上げたとしても、読み出しと書き出し先の双方のデータストアのリソース消費量が増加する。
さらに、実行中に失敗する可能性を考慮すると、実行時間の保証が難しくなるかつ、処理の冪等性を求められる。

時系列データベースのアーキテクチャでは、これをデータストアのレコード単位のTTLを利用して解決した。
具体的には、データストアに書き込むときに、レコードに対してTTL（Time To Live）を設定し、TTLが期限切れになったタイミングで、トリガーを起動し、期限切れレコードを別のデータストアへ書き込む。
実装として、DynamoDB StreamsとLambda Triggersの組み合わせ[dyn01]とDynamoDBのTTL[dyn02]を利用し、DynamoDBからS3へデータを移動させた。
これにより、パイプライン処理を、バッチ処理ではなく、レコード単位のイベント駆動型処理に置き換えられた。

のちに、TTLを用いたデータパイプラインアーキテクチャを時系列データベース以外のデータパイプラインに適用できないかを考えた。
例えば、機械学習の学習モデルの定期更新や、マルチテナント環境における大量のSSL/TLS証明書[mat17]の定期更新などがある。

アイデアの要点は、**処理とデータとタイマーの一体化**だ。
従来は、cronのような単一のタイムスケジューラーがジョブを実行していた。
一方、提案するアーキテクチャでは、データに紐付いたタイマーがジョブを起動する。
このにより、従来手法と比較し、スケーラブルかつ細かい粒度で制御しやすい定期データパイプライン処理ができる。
起爆装置と爆薬とタイマーを一体化した時限信管(Time Fuze)に似ていることから、このアーキテクチャを「TimeFuzeアーキテクチャ」と名付けてみた。

以降では、TimeFuzeアーキテクチャの詳細と実装手段、アプリケーション適用について議論する。

# 提案手法

## TimeFuzeアーキテクチャ

TimeFuzeアーキテクチャの動作フローを以下の図に示す。

f:id:y_uuki:20171219005814p:image

DataSourceはデータパイプラインの読み出し側を指し、DataDestinationは書き出し側を指す。
TriggerはDataSourceレコード単位のパイプライン処理を実行する。

まず、DataSourceに対して、Triggerを実行したい時刻を表すTTLと共にデータレコードを書き込む。
次に、TTLの期限切れ(expire)を検知し、Triggerに期限切れしたレコードを渡す。
さらに、Triggerが渡されたレコードをもとに所定の処理を実行し、DataDestinationに対して、結果を書き込む。
Triggerでは、その他のAPIやデータストアからデータを取得することもある。
DataDestinationは、DataSourceと同一のデータストアでもよい。
前述の学習モデルの更新や証明書更新の例では、DataSourceとDataDestinationは同一のデータストアを利用することを想定している。

## TimeFuzeのメリット

TimeFuzeアーキテクチャには以下のメリットがある。

- a) 並行処理を前提としたアーキテクチャであり、スケールさせやすいこと
- b) エラーからの回復処理が容易であること
- c) タイムスケジューラとバッチ処理のためのホストもしくはクラスタの構築・運用が不要であること
- d) レコード単位でタイマーをセットするため、ジョブの実行頻度をレコード単位で調整可能

a) について、バッチ処理の場合、マルチコア・マルチホストスケールさせるまたはI/O多重化するための並行処理実装を開発者に要求する。
TimeFuzeでは、レコード単位でトリガー処理を記述するため、スケールさせやすい。
b) について、TimeFuzeでは、1レコード分の処理を書けばよいため、エラー発生時にリトライする場合、どこまで処理を終えたかを記録するといった回復処理のための実装が必要がない。

## TimeFuzeの実装

実装として、Amazon DynamoDBとAmazon Lambdaを利用する例と、Redisを利用する例をあげる。

### Amazon DynamoDBおよびAmazon Lambda

Amazon DynamoDBは、フルマネージド型のNoSQLデータベースサービスである。
Amazon Lambdaは、任意のイベントを入力として任意の処理をFunctionとして登録しておくと、イベント発火を契機にFunctionを呼び出せる。
これらを組み合わせ、DynamoDB上のレコードに対する登録、更新、削除のイベントを契機に、Lambda Functionをトリガーとして実行できる。
DynamoDBはTTLをサポートしており、TTL expiredイベントを契機にLambda Functionを実行できる。

DynamoDBをDataSourceとして、トリガー処理にLambdaを利用することで、TimeFuzeアーキテクチャを素直に実装できる。

### Redis

Redisは多彩なデータ構造をもつインメモリDBであり、昨今のWebアプリケーションのデータストアの一つとして、広く利用されている。
RedisはKeyspace通知[[rednot]](https://redis.io/topics/notifications)機能をもち、キーに対するイベントをPub/Subにより、購読者にメッセージ通知できる。
Keyspace通知を利用し、DynamoDB同様にトリガー処理を実現できる。

ただし、実運用のためのトリガー処理を実現するには、イベント通知以外に、通知するイベントの永続化とイベントを受信し処理するトリガーの実装が必要となる。
Redis自体は、後者の2つをサポートしないため、アプリケーション開発者が汎用的に利用できる実装を提示したい。

そこで、以前筆者が開発したジョブキューシステム[[yuu14]](http://blog.yuuk.io/entry/go-and-mysql-jobqueue)Fireworqに着目する。
Fireworqでは、ジョブの永続化をサポートし、所定のインタフェースを満たしていれば任意の言語で開発したWebアプリケーションサーバに対してジョブ実行を依頼できる。
RedisのKeyspace通知とFireworqを組み合わせることにより、メッセージの永続化をサポートしつつ、任意の言語によるトリガー処理を実現できる。
ただし、RedisにKeyspace通知を受信し、Fireworqへ投稿するコンポーネントを新たに実装する必要がある。

## TimeFuzeの具体的なアプリケーションへの適用

自分の最近の業務経験から、時系列データの異常検知と大規模SSL/TLS証明書管理アプリケーションへのTimeFuzeアーキテクチャの適用を考えた。

### 時系列データの異常検知

機械学習をWebサービスに導入すると、日次パイプラインにより、学習モデルを更新することがある。
DataSource上のモデルの更新処理をTriggerとして登録し、モデル更新時にTTLを1日後にセットして再書き込みすれば、日次パイプラインとして機能する。

時系列データによる異常検知では、収集したメトリック系列もしくはメトリック系列の集合に対して、学習モデルを構築する。
学習モデル構築後に収集されるメトリックに対応するため、学習モデルを定期的に更新する必要がある。

このアプリケーションにTimeFuzeアーキテクチャを適応することを考える。
学習モデルを更新するのみで、学習モデルを他のデータストアに移動させる必要はないため、DataSourceとDataDestinationは同一のデータストアとなる。
各学習モデルのレコードにTTLを設定し、Triggerが外部データストアからメトリックを取得し、学習処理を実行したのちにDataDestinationに対して上書き更新する。

### 大規模SSL/TLS証明書管理

ブログサービスやレンタルサーバーサービスのようなマルチテナント環境[[pep17]](https://tech.pepabo.com/2017/08/22/lolipop-free-ssl)にて、大量のSSL/TLS証明書を管理し、数ヶ月ごとに更新するケースがある。Let's Encrypt[letenc]の場合、証明書の期限は3ヶ月となる。

[mat17]では、サーバ証明書と秘密鍵をWebサーバ上のファイルシステムに格納するのではなく、データベースに格納し動的取得するアーキテクチャが提案されている。
データベース上の証明書と秘密鍵を定期的に更新するために、TimeFuzeアーキテクチャを適用することを考える。
各ドメインに対する証明書および秘密鍵のレコードにTTLを設定し、Triggerが証明書を再取得し、DataDestinationへ上書きする。
Let's Encryptの場合、ACMEプロトコルにより証明書を自動発行できる。

# 考察

## TimeFuzeのデメリット

TimeFuzeアーキテクチャはあらゆる定期データパイプラインに適用できるわけではない。

アーキテクチャレベルでは、Triggerがレコード単位でジョブを実行するため、DataSource上の複数のレコードをマージする必要がある処理をしづらいというデメリットがある。
従来手法であれば、DataSource上のレコードをグループ化して読み出し、マージ処理することは容易である。
一方、TimeFuzeアーキテクチャでは、マージする必要がないように最初から1つのレコードにまとめて書き込む必要がある。

さらに、実装レベルでは、TTLを利用することのデメリットとして、データの一貫性と、ジョブ実行タイミング制御の困難性がある。
前者では、レコードが削除されてから更新されるまでレコードを参照できない期間があり、アプリケーションに工夫を要求する。
後者は、TTLの期限切れを過ぎてから実際に削除されるまでのディレイが大きいと、開発者が意図したタイミングよりも遅れてジョブが実行されることがありえる。
DynamoDBのTTL実装の場合、ベストエフォートベースでTTL期限切れ以降2日以内に削除することを目指している[[dyn03]](https://aws.amazon.com/dynamodb/faqs/#ttl)。

## TimeFuzeのデメリットの解決

TTLのデータの一貫性の問題は、TTLをタイマーとして利用するのではなく、設定した時刻を経過したイベントのみを発行し、レコードを削除しない機能をデータストアに組み込むことで解決できる。

ジョブ実行タイミング制御の問題は、RedisやCassandraなどTTLをサポートしたデータベース実装を調査し、ディレイ時間を計測する必要がある。

# むすび

定期的なデータパイプライン処理は、Webサービス開発ではよく採用されるデザインパターンである。
単一のタイムスケジューラによる従来手法では、レコード数に対するスケーラビリティ・エラー回復処理・サーバ運用効率・ジョブ実行頻度の細かい粒度での制御に課題があった。
そこで、この記事では、処理とデータとタイマーを一体化したTimeFuzeアーキテクチャを提案し、従来手法の課題の解決を構想した。
さらに、時系列データベースアーキテクチャ、時系列データの異常検知、大規模SSL/TLS証明書管理の各アプリケーションへの適用可能性を示した。

今後の取り組みとして、既存の定期データパイプラインの課題をサーベイし整理し、既存データストア実装のTTLディレイ時間の調査、TTLではなくTime to Eventを既存のデータストアへ組み込むことを考えている。

## 参考文献

- [yuu17]: [http://blog.yuuk.io/entry/the-rebuild-of-tsdb-on-cloud:title:bookmark]
- [Bet17]: Betsy Beyer, Chris Jones, Jennifer Petoff, Niall Richard Murphy編 澤田武男 関根達夫 細川一茂 矢吹大輔 監訳 Sky株式会社 玉川竜司 訳,「SRE サイトリライアビリティエンジニアリング ――Googleの信頼性を支えるエンジニアリングチーム」,オライリー・ジャパン,2017/08, https://www.oreilly.co.jp/books/9784873117911/
- [dyn00]: Amazon Web Services, Inc., "Amazon DynamoDB", https://aws.amazon.com/jp/dynamodb/
- [dyn01]: Amazon Web Services, Inc., "DynamoDB Streams and AWS Lambda Triggers", http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Streams.Lambda.html
- [dyn02]: Amazon Web Services, Inc., "Time To Live - Amazon DynamoDB", http://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/TTL.html
- [dyn03]: Amazon Web Services, Inc., "FAQs - Amazon DynamoDB", https://aws.amazon.com/dynamodb/faqs/#ttl
- [mat17]: 松本亮介, 三宅 悠介, 力武 健次, 栗林 健太郎, 「高集積マルチテナントWebサーバの大規模証明書管理と実運用上の評価」, 情報処理学会研究報告インターネットと運用技術（IOT）,2017-IOT-39, Vol.14, pp.1-8, 2017年9月
- [pep17]: [https://tech.pepabo.com/2017/08/22/lolipop-free-ssl/:title]
- [rednot]: [https://redis.io/topics/notifications:title]
- [yuu14]: [http://blog.yuuk.io/entry/go-and-mysql-jobqueue:title]
- [letenc]: Internet Security Research Group (ISRG), Let's Encrypt - Free SSL/TLS Certificates, https://letsencrypt.org/.

<!-- # 概要 -->
<!--  -->
<!--  -->
<!-- しかし、このバッチ処理手法には、スケーラビリティと実行時のエラー回復に関する2つの問題がある。 -->
<!-- まず一般に、データベース上の処理対象レコード数が増加するにつれ、バッチ処理の実行時間が増大するため、レコード数に対してスケールしない。 -->
<!-- 次に、実行途中にエラーが発生した場合、再試行したとしても結果が等しくなるように、バッチ処理プログラムを設計する必要がある。 -->
<!--  -->
<!-- これらの2つの問題に対して、DBMSのTTL期限切れイベントをトリガーとし、予め登録された任意の処理を実行するアーキテクチャを考えた。 -->
<!-- このアーキテクチャにより、データレコードごとに処理を記述するため、バッチ処理と比較して、再試行時を考慮したコードを書きやすい。 -->
<!-- さらに、レコード単位のトリガー処理の場合、他の処理プロセスとデータ競合しないため、レコード数に対して処理時間をスケールさせやすい。 -->
<!--  -->
<!-- # はじめに -->
<!--  -->
<!-- Webサービスにおけるサーバサイドの典型的な処理実行方式は、ユーザのクライアント端末からのリクエストに対して同期処理するか、非同期処理するか、ストリーミング処理するかのいずれかである。 -->
<!-- 同期処理では、一般的に、ユーザのリクエストをWebサーバが受信し、Webサーバがユーザに対してレスポンスを送信する。 -->
<!-- 非同期処理では、ユーザのリクエストを契機に遅延処理を登録するイベントトリガー方式と、任意の時刻または任意の周期で処理するタイムトリガー方式 -->
<!-- ユーザのリクエストを契機に、遅延処理イベントとして登録し、遅延処理するか、もしくは任意の時間に処理 -->
<!--  -->
<!-- <!-- - FaaSでいうところのイベントトリガー型スケジューラー --> -->
<!--  -->
<!-- # タイムトリガーの既存手法と課題 -->
<!--  -->
<!-- <!-- - レコード数が増加するにつれ実行時間が増大する --> -->
<!-- <!-- - 処理分割が必要 --> -->
<!--  -->
<!-- # 提案手法 -->
<!--  -->
<!--  -->
<!-- # 実験と考察 -->
<!--  -->
<!-- <!-- - 複数のレコードをまとめる処理がしづらくなる --> -->
<!-- <!-- - バースト制御が難しくなる --> -->
<!-- <!--  --> -->
<!-- <!-- - TTLのexpire時刻と実際の削除時刻のディレイが大きいのはなぜか --> -->
<!-- <!-- - なぜRDBMSでは、TTLがないか --> -->
<!--  -->
<!-- # むすび -->

